{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Description</th>\n",
       "      <th>Auteurs</th>\n",
       "      <th>Image</th>\n",
       "      <th>Lien Google</th>\n",
       "      <th>Editeur</th>\n",
       "      <th>Date publication</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Nb scores</th>\n",
       "      <th>Id</th>\n",
       "      <th>Prix</th>\n",
       "      <th>User_id</th>\n",
       "      <th>Nom lecteur</th>\n",
       "      <th>revue/utilité</th>\n",
       "      <th>revue/score</th>\n",
       "      <th>revue/heure</th>\n",
       "      <th>revue/résumé</th>\n",
       "      <th>revue/texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Church of Christ: A Biblical Ecclesiology ...</td>\n",
       "      <td>In The Church of Christ: A Biblical Ecclesiolo...</td>\n",
       "      <td>['Everett Ferguson']</td>\n",
       "      <td>http://books.google.com/books/content?id=kVqRa...</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;p...</td>\n",
       "      <td>Wm. B. Eerdmans Publishing</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0802841899</td>\n",
       "      <td>25.97</td>\n",
       "      <td>ARI272XF8TOL4</td>\n",
       "      <td>Christopher J. Bray</td>\n",
       "      <td>74/81</td>\n",
       "      <td>5.0</td>\n",
       "      <td>955411200</td>\n",
       "      <td>Ecclesiological Milestone</td>\n",
       "      <td>With the publication of Everett Ferguson's boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Church of Christ: A Biblical Ecclesiology ...</td>\n",
       "      <td>In The Church of Christ: A Biblical Ecclesiolo...</td>\n",
       "      <td>['Everett Ferguson']</td>\n",
       "      <td>http://books.google.com/books/content?id=kVqRa...</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;p...</td>\n",
       "      <td>Wm. B. Eerdmans Publishing</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=kVqRaiPlx88C&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0802841899</td>\n",
       "      <td>25.97</td>\n",
       "      <td>A36TPZSH8LBT1</td>\n",
       "      <td>haskell</td>\n",
       "      <td>2/3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1311465600</td>\n",
       "      <td>Early Christian development of the Church</td>\n",
       "      <td>Everett Ferguson approaches the subject of ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>The Battleship Bismarck</td>\n",
       "      <td>The Bismarck is perhaps the most famous – and ...</td>\n",
       "      <td>['Stefan Draminski']</td>\n",
       "      <td>http://books.google.com/books/content?id=nxttD...</td>\n",
       "      <td>http://books.google.nl/books?id=nxttDwAAQBAJ&amp;p...</td>\n",
       "      <td>Bloomsbury Publishing</td>\n",
       "      <td>20/09/2018</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "      <td>['History']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0887402216</td>\n",
       "      <td>34.95</td>\n",
       "      <td>A30IUAABSEHEPI</td>\n",
       "      <td>Lawrence Duckles</td>\n",
       "      <td>9/9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1055980800</td>\n",
       "      <td>The Battleship Bismarck reviewed</td>\n",
       "      <td>This book is both a history and a photo album ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>The Battleship Bismarck</td>\n",
       "      <td>The Bismarck is perhaps the most famous – and ...</td>\n",
       "      <td>['Stefan Draminski']</td>\n",
       "      <td>http://books.google.com/books/content?id=nxttD...</td>\n",
       "      <td>http://books.google.nl/books?id=nxttDwAAQBAJ&amp;p...</td>\n",
       "      <td>Bloomsbury Publishing</td>\n",
       "      <td>20/09/2018</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "      <td>['History']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0887402216</td>\n",
       "      <td>34.95</td>\n",
       "      <td>A29SCEAL3JPMYW</td>\n",
       "      <td>Tim Grasshoff</td>\n",
       "      <td>0/0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1217808000</td>\n",
       "      <td>nice historical pictures</td>\n",
       "      <td>I like this book first one I've seen with so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Beginner's Yoruba (Hippocrene Beginner's Series)</td>\n",
       "      <td>\"Beginner's Yoruba\" is now available with two ...</td>\n",
       "      <td>['Kayode J. Fakinlede']</td>\n",
       "      <td>http://books.google.com/books/content?id=xLe4n...</td>\n",
       "      <td>http://books.google.nl/books?id=xLe4nWzeSw0C&amp;p...</td>\n",
       "      <td>Hippocrene Books</td>\n",
       "      <td>2005</td>\n",
       "      <td>http://books.google.nl/books?id=xLe4nWzeSw0C&amp;d...</td>\n",
       "      <td>['Foreign Language Study']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0781810698</td>\n",
       "      <td>19.77</td>\n",
       "      <td>A1F0EV2MBF208I</td>\n",
       "      <td>Olena Y. Rabinowitz \"Book lover\"</td>\n",
       "      <td>14/14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1156291200</td>\n",
       "      <td>Very authentic</td>\n",
       "      <td>This is my first encounter with Yoruba and I h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Titre  \\\n",
       "8   The Church of Christ: A Biblical Ecclesiology ...   \n",
       "9   The Church of Christ: A Biblical Ecclesiology ...   \n",
       "57                            The Battleship Bismarck   \n",
       "58                            The Battleship Bismarck   \n",
       "74   Beginner's Yoruba (Hippocrene Beginner's Series)   \n",
       "\n",
       "                                          Description  \\\n",
       "8   In The Church of Christ: A Biblical Ecclesiolo...   \n",
       "9   In The Church of Christ: A Biblical Ecclesiolo...   \n",
       "57  The Bismarck is perhaps the most famous – and ...   \n",
       "58  The Bismarck is perhaps the most famous – and ...   \n",
       "74  \"Beginner's Yoruba\" is now available with two ...   \n",
       "\n",
       "                    Auteurs  \\\n",
       "8      ['Everett Ferguson']   \n",
       "9      ['Everett Ferguson']   \n",
       "57     ['Stefan Draminski']   \n",
       "58     ['Stefan Draminski']   \n",
       "74  ['Kayode J. Fakinlede']   \n",
       "\n",
       "                                                Image  \\\n",
       "8   http://books.google.com/books/content?id=kVqRa...   \n",
       "9   http://books.google.com/books/content?id=kVqRa...   \n",
       "57  http://books.google.com/books/content?id=nxttD...   \n",
       "58  http://books.google.com/books/content?id=nxttD...   \n",
       "74  http://books.google.com/books/content?id=xLe4n...   \n",
       "\n",
       "                                          Lien Google  \\\n",
       "8   http://books.google.nl/books?id=kVqRaiPlx88C&p...   \n",
       "9   http://books.google.nl/books?id=kVqRaiPlx88C&p...   \n",
       "57  http://books.google.nl/books?id=nxttDwAAQBAJ&p...   \n",
       "58  http://books.google.nl/books?id=nxttDwAAQBAJ&p...   \n",
       "74  http://books.google.nl/books?id=xLe4nWzeSw0C&p...   \n",
       "\n",
       "                       Editeur Date publication  \\\n",
       "8   Wm. B. Eerdmans Publishing             1996   \n",
       "9   Wm. B. Eerdmans Publishing             1996   \n",
       "57       Bloomsbury Publishing       20/09/2018   \n",
       "58       Bloomsbury Publishing       20/09/2018   \n",
       "74            Hippocrene Books             2005   \n",
       "\n",
       "                                             infoLink  \\\n",
       "8   http://books.google.nl/books?id=kVqRaiPlx88C&d...   \n",
       "9   http://books.google.nl/books?id=kVqRaiPlx88C&d...   \n",
       "57  https://play.google.com/store/books/details?id...   \n",
       "58  https://play.google.com/store/books/details?id...   \n",
       "74  http://books.google.nl/books?id=xLe4nWzeSw0C&d...   \n",
       "\n",
       "                         Genre  Nb scores          Id   Prix         User_id  \\\n",
       "8                 ['Religion']        5.0  0802841899  25.97   ARI272XF8TOL4   \n",
       "9                 ['Religion']        5.0  0802841899  25.97   A36TPZSH8LBT1   \n",
       "57                 ['History']        1.0  0887402216  34.95  A30IUAABSEHEPI   \n",
       "58                 ['History']        1.0  0887402216  34.95  A29SCEAL3JPMYW   \n",
       "74  ['Foreign Language Study']        1.0  0781810698  19.77  A1F0EV2MBF208I   \n",
       "\n",
       "                         Nom lecteur revue/utilité  revue/score  revue/heure  \\\n",
       "8                Christopher J. Bray         74/81          5.0    955411200   \n",
       "9                            haskell           2/3          5.0   1311465600   \n",
       "57                  Lawrence Duckles           9/9          3.0   1055980800   \n",
       "58                     Tim Grasshoff           0/0          4.0   1217808000   \n",
       "74  Olena Y. Rabinowitz \"Book lover\"         14/14          4.0   1156291200   \n",
       "\n",
       "                                 revue/résumé  \\\n",
       "8                   Ecclesiological Milestone   \n",
       "9   Early Christian development of the Church   \n",
       "57           The Battleship Bismarck reviewed   \n",
       "58                   nice historical pictures   \n",
       "74                             Very authentic   \n",
       "\n",
       "                                          revue/texte  \n",
       "8   With the publication of Everett Ferguson's boo...  \n",
       "9   Everett Ferguson approaches the subject of ear...  \n",
       "57  This book is both a history and a photo album ...  \n",
       "58  I like this book first one I've seen with so m...  \n",
       "74  This is my first encounter with Yoruba and I h...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data_fusion_little.csv')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_polarite = data[['Titre', 'revue/texte']]\n",
    "Y_polarite = data['revue/score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def encode_simple(X_polarite, Y_polarite):\n",
    "    # Séparer les données en train et test\n",
    "    X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite = train_test_split(\n",
    "        X_polarite, Y_polarite, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Copier explicitement pour éviter les warnings\n",
    "    X_train_polarite = X_train_polarite.copy()\n",
    "    X_test_polarite = X_test_polarite.copy()\n",
    "\n",
    "    # Initialiser l'encodeur avec gestion des valeurs inconnues\n",
    "    titre_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    texte_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "    # Appliquer l'encodage\n",
    "    X_train_polarite['Titre'] = titre_encoder.fit_transform(X_train_polarite[['Titre']]).astype(float)\n",
    "    X_train_polarite['revue/texte'] = texte_encoder.fit_transform(X_train_polarite[['revue/texte']]).astype(float)\n",
    "\n",
    "    X_test_polarite['Titre'] = titre_encoder.transform(X_test_polarite[['Titre']]).astype(float)\n",
    "    X_test_polarite['revue/texte'] = texte_encoder.transform(X_test_polarite[['revue/texte']]).astype(float)\n",
    "\n",
    "    return X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def encode_tfidf(X_polarite, Y_polarite):\n",
    "    # Séparer les données en train et test\n",
    "    X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite = train_test_split(\n",
    "        X_polarite, Y_polarite, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Initialiser deux vectorizers TF-IDF (un pour chaque colonne)\n",
    "    tfidf_titre = TfidfVectorizer()\n",
    "    tfidf_texte = TfidfVectorizer()\n",
    "\n",
    "    # Encodage des titres\n",
    "    X_train_polarite_titre_tfidf = tfidf_titre.fit_transform(X_train_polarite['Titre'])\n",
    "    X_test_polarite_titre_tfidf = tfidf_titre.transform(X_test_polarite['Titre'])\n",
    "\n",
    "    # Encodage des textes\n",
    "    X_train_polarite_texte_tfidf = tfidf_texte.fit_transform(X_train_polarite['revue/texte'])\n",
    "    X_test_polarite_texte_tfidf = tfidf_texte.transform(X_test_polarite['revue/texte'])\n",
    "\n",
    "    # Combiner les deux colonnes encodées\n",
    "    X_train_polarite = hstack([X_train_polarite_titre_tfidf, X_train_polarite_texte_tfidf])\n",
    "    X_test_polarite = hstack([X_test_polarite_titre_tfidf, X_test_polarite_texte_tfidf])\n",
    "\n",
    "    return X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cedric\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 990462.0625 - mae: 615.6398 - val_loss: 76.8154 - val_mae: 7.7686\n",
      "Epoch 2/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14495.5215 - mae: 69.9925 - val_loss: 29.3426 - val_mae: 5.1269\n",
      "Epoch 3/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4277.0596 - mae: 29.8479 - val_loss: 12.9890 - val_mae: 3.4203\n",
      "Epoch 4/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1571.9329 - mae: 15.2611 - val_loss: 12.2349 - val_mae: 3.3126\n",
      "Epoch 5/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1240.9801 - mae: 10.8610 - val_loss: 12.4768 - val_mae: 3.3492\n",
      "Epoch 6/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 669.4883 - mae: 7.9034 - val_loss: 10.5625 - val_mae: 3.0518\n",
      "Epoch 7/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 371.0244 - mae: 6.4013 - val_loss: 13.0780 - val_mae: 3.4391\n",
      "Epoch 8/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 343.5607 - mae: 5.7319 - val_loss: 9.1667 - val_mae: 2.8230\n",
      "Epoch 9/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 232.8902 - mae: 4.8214 - val_loss: 9.1864 - val_mae: 2.8227\n",
      "Epoch 10/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 248.6451 - mae: 4.6587 - val_loss: 9.6420 - val_mae: 2.9056\n",
      "Epoch 11/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 166.4551 - mae: 4.1151 - val_loss: 9.1924 - val_mae: 2.8338\n",
      "Epoch 12/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 154.9322 - mae: 4.0321 - val_loss: 10.2919 - val_mae: 3.0223\n",
      "Epoch 13/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 81.5711 - mae: 3.4838 - val_loss: 10.3532 - val_mae: 3.0134\n",
      "Epoch 14/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 153.0964 - mae: 3.5619 - val_loss: 8.3254 - val_mae: 2.6882\n",
      "Epoch 15/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 61.5998 - mae: 3.2254 - val_loss: 7.9857 - val_mae: 2.6306\n",
      "Epoch 16/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56.2795 - mae: 3.0677 - val_loss: 6.1775 - val_mae: 2.2662\n",
      "Epoch 17/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35.7374 - mae: 2.8511 - val_loss: 4.6961 - val_mae: 1.9045\n",
      "Epoch 18/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53.7392 - mae: 2.9256 - val_loss: 5.4354 - val_mae: 2.1141\n",
      "Epoch 19/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54.2513 - mae: 2.8131 - val_loss: 6.7253 - val_mae: 2.4078\n",
      "Epoch 20/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35.8309 - mae: 2.7060 - val_loss: 6.4435 - val_mae: 2.3593\n",
      "Epoch 21/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.4505 - mae: 2.3609 - val_loss: 3.5264 - val_mae: 1.6153\n",
      "Epoch 22/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 23.2922 - mae: 2.3507 - val_loss: 4.4624 - val_mae: 1.9220\n",
      "Epoch 23/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16.0811 - mae: 2.2768 - val_loss: 4.9063 - val_mae: 2.0451\n",
      "Epoch 24/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.7790 - mae: 2.1845 - val_loss: 5.5239 - val_mae: 2.1913\n",
      "Epoch 25/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16.9526 - mae: 2.1993 - val_loss: 3.6486 - val_mae: 1.7407\n",
      "Epoch 26/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16.9583 - mae: 2.0637 - val_loss: 2.3826 - val_mae: 1.3142\n",
      "Epoch 27/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.1041 - mae: 1.9478 - val_loss: 3.4389 - val_mae: 1.7106\n",
      "Epoch 28/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.4596 - mae: 1.9335 - val_loss: 4.0248 - val_mae: 1.8775\n",
      "Epoch 29/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.7489 - mae: 1.8165 - val_loss: 3.7734 - val_mae: 1.8213\n",
      "Epoch 30/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7797 - mae: 1.6658 - val_loss: 2.4909 - val_mae: 1.4491\n",
      "Epoch 31/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8774 - mae: 1.5518 - val_loss: 1.9269 - val_mae: 1.2325\n",
      "Epoch 32/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1472 - mae: 1.4603 - val_loss: 1.6574 - val_mae: 1.1056\n",
      "Epoch 33/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32.6767 - mae: 1.6413 - val_loss: 2.6010 - val_mae: 1.4997\n",
      "Epoch 34/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.4522 - mae: 1.3300 - val_loss: 1.6385 - val_mae: 1.1315\n",
      "Epoch 35/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6911 - mae: 1.3616 - val_loss: 2.0370 - val_mae: 1.3226\n",
      "Epoch 36/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1692 - mae: 1.2235 - val_loss: 1.8252 - val_mae: 1.2437\n",
      "Epoch 37/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9355 - mae: 1.1140 - val_loss: 1.5527 - val_mae: 1.1097\n",
      "Epoch 38/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3926 - mae: 1.0753 - val_loss: 1.4048 - val_mae: 1.0199\n",
      "Epoch 39/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4128 - mae: 0.9734 - val_loss: 1.2960 - val_mae: 0.9315\n",
      "Epoch 40/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3234 - mae: 0.9107 - val_loss: 1.2313 - val_mae: 0.8979\n",
      "Epoch 41/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.5669 - mae: 0.9235 - val_loss: 1.2022 - val_mae: 0.8758\n",
      "Epoch 42/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2394 - mae: 0.8704 - val_loss: 1.1893 - val_mae: 0.8588\n",
      "Epoch 43/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3651 - mae: 0.8561 - val_loss: 1.1855 - val_mae: 0.8472\n",
      "Epoch 44/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4579 - mae: 0.8638 - val_loss: 1.1849 - val_mae: 0.8420\n",
      "Epoch 45/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2013 - mae: 0.8348 - val_loss: 1.1850 - val_mae: 0.8383\n",
      "Epoch 46/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1716 - mae: 0.8136 - val_loss: 1.1851 - val_mae: 0.8372\n",
      "Epoch 47/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3629 - mae: 0.8534 - val_loss: 1.1851 - val_mae: 0.8373\n",
      "Epoch 48/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1866 - mae: 0.8318 - val_loss: 1.1852 - val_mae: 0.8368\n",
      "Epoch 49/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1076 - mae: 0.8158 - val_loss: 1.1852 - val_mae: 0.8367\n",
      "Epoch 50/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9936 - mae: 0.8391 - val_loss: 1.1854 - val_mae: 0.8351\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - loss: 1.1000 - mae: 0.8204\n",
      "Test Loss: 1.1825599670410156\n",
      "Test MAE: 0.8419859409332275\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Encodage simple\n",
    "X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite = encode_simple(X_polarite, Y_polarite)\n",
    "\n",
    "# Convertir en numpy arrays pour TensorFlow\n",
    "X_train_polarite = X_train_polarite.values.astype(np.float32)\n",
    "X_test_polarite = X_test_polarite.values.astype(np.float32)\n",
    "Y_train_polarite = Y_train_polarite.values.astype(np.float32)\n",
    "Y_test_polarite = Y_test_polarite.values.astype(np.float32)\n",
    "\n",
    "# Définir le modèle\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_polarite.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='linear')  # Utiliser 'linear' pour une régression\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_polarite, Y_train_polarite, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss, mae = model.evaluate(X_test_polarite, Y_test_polarite)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "# Enregistrer le modèle (utiliser save() au lieu de pickle)\n",
    "os.makedirs('models2', exist_ok=True)  # Créer le dossier si inexistant\n",
    "model.save('models2/deepl_regression_simple.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cedric\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 6.5686 - mae: 2.0605 - val_loss: 1.0902 - val_mae: 0.8611\n",
      "Epoch 2/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - loss: 1.3407 - mae: 0.9364 - val_loss: 0.9533 - val_mae: 0.7836\n",
      "Epoch 3/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 1.1274 - mae: 0.8577 - val_loss: 0.8993 - val_mae: 0.7537\n",
      "Epoch 4/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.9681 - mae: 0.7905 - val_loss: 0.9644 - val_mae: 0.7984\n",
      "Epoch 5/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.9135 - mae: 0.7662 - val_loss: 0.8701 - val_mae: 0.7282\n",
      "Epoch 6/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - loss: 0.8058 - mae: 0.7166 - val_loss: 0.8826 - val_mae: 0.7376\n",
      "Epoch 7/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - loss: 0.7542 - mae: 0.6938 - val_loss: 0.8890 - val_mae: 0.7487\n",
      "Epoch 8/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.6888 - mae: 0.6628 - val_loss: 0.8417 - val_mae: 0.6930\n",
      "Epoch 9/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.6179 - mae: 0.6235 - val_loss: 0.8278 - val_mae: 0.6859\n",
      "Epoch 10/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - loss: 0.5508 - mae: 0.5960 - val_loss: 0.8556 - val_mae: 0.7154\n",
      "Epoch 11/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - loss: 0.5261 - mae: 0.5788 - val_loss: 0.8212 - val_mae: 0.6765\n",
      "Epoch 12/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - loss: 0.4949 - mae: 0.5629 - val_loss: 0.8430 - val_mae: 0.7073\n",
      "Epoch 13/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - loss: 0.4489 - mae: 0.5389 - val_loss: 0.8142 - val_mae: 0.6698\n",
      "Epoch 14/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - loss: 0.4249 - mae: 0.5252 - val_loss: 0.8113 - val_mae: 0.6702\n",
      "Epoch 15/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - loss: 0.3871 - mae: 0.4942 - val_loss: 0.8214 - val_mae: 0.6747\n",
      "Epoch 16/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - loss: 0.3637 - mae: 0.4826 - val_loss: 0.8144 - val_mae: 0.6539\n",
      "Epoch 17/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - loss: 0.3359 - mae: 0.4647 - val_loss: 0.8226 - val_mae: 0.6779\n",
      "Epoch 18/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - loss: 0.3106 - mae: 0.4446 - val_loss: 0.8142 - val_mae: 0.6520\n",
      "Epoch 19/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - loss: 0.2914 - mae: 0.4288 - val_loss: 0.8173 - val_mae: 0.6644\n",
      "Epoch 20/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - loss: 0.2779 - mae: 0.4187 - val_loss: 0.8080 - val_mae: 0.6497\n",
      "Epoch 21/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - loss: 0.2470 - mae: 0.3948 - val_loss: 0.8037 - val_mae: 0.6601\n",
      "Epoch 22/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.2346 - mae: 0.3826 - val_loss: 0.8015 - val_mae: 0.6411\n",
      "Epoch 23/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.2281 - mae: 0.3818 - val_loss: 0.8056 - val_mae: 0.6585\n",
      "Epoch 24/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - loss: 0.2081 - mae: 0.3622 - val_loss: 0.8036 - val_mae: 0.6561\n",
      "Epoch 25/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.1879 - mae: 0.3444 - val_loss: 0.7978 - val_mae: 0.6266\n",
      "Epoch 26/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - loss: 0.1777 - mae: 0.3326 - val_loss: 0.7941 - val_mae: 0.6385\n",
      "Epoch 27/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - loss: 0.1708 - mae: 0.3249 - val_loss: 0.7922 - val_mae: 0.6349\n",
      "Epoch 28/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 51ms/step - loss: 0.1584 - mae: 0.3111 - val_loss: 0.7928 - val_mae: 0.6398\n",
      "Epoch 29/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1520 - mae: 0.3046 - val_loss: 0.8008 - val_mae: 0.6247\n",
      "Epoch 30/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - loss: 0.1492 - mae: 0.2993 - val_loss: 0.7973 - val_mae: 0.6272\n",
      "Epoch 31/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - loss: 0.1354 - mae: 0.2832 - val_loss: 0.7855 - val_mae: 0.6238\n",
      "Epoch 32/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - loss: 0.1343 - mae: 0.2828 - val_loss: 0.7862 - val_mae: 0.6318\n",
      "Epoch 33/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - loss: 0.1290 - mae: 0.2733 - val_loss: 0.7850 - val_mae: 0.6166\n",
      "Epoch 34/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1244 - mae: 0.2685 - val_loss: 0.7970 - val_mae: 0.6189\n",
      "Epoch 35/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1186 - mae: 0.2601 - val_loss: 0.8009 - val_mae: 0.6060\n",
      "Epoch 36/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1138 - mae: 0.2565 - val_loss: 0.7958 - val_mae: 0.6055\n",
      "Epoch 37/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1141 - mae: 0.2506 - val_loss: 0.7944 - val_mae: 0.6145\n",
      "Epoch 38/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1143 - mae: 0.2523 - val_loss: 0.7972 - val_mae: 0.6006\n",
      "Epoch 39/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1134 - mae: 0.2484 - val_loss: 0.7932 - val_mae: 0.6020\n",
      "Epoch 40/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - loss: 0.1009 - mae: 0.2339 - val_loss: 0.7926 - val_mae: 0.6079\n",
      "Epoch 41/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.1004 - mae: 0.2315 - val_loss: 0.7914 - val_mae: 0.6026\n",
      "Epoch 42/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1029 - mae: 0.2305 - val_loss: 0.7908 - val_mae: 0.6075\n",
      "Epoch 43/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 70ms/step - loss: 0.0954 - mae: 0.2227 - val_loss: 0.7951 - val_mae: 0.6036\n",
      "Epoch 44/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - loss: 0.0958 - mae: 0.2206 - val_loss: 0.8008 - val_mae: 0.6005\n",
      "Epoch 45/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 78ms/step - loss: 0.0989 - mae: 0.2228 - val_loss: 0.7930 - val_mae: 0.6057\n",
      "Epoch 46/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 48ms/step - loss: 0.0998 - mae: 0.2209 - val_loss: 0.7940 - val_mae: 0.6011\n",
      "Epoch 47/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - loss: 0.0932 - mae: 0.2172 - val_loss: 0.7932 - val_mae: 0.6096\n",
      "Epoch 48/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.0978 - mae: 0.2178 - val_loss: 0.7950 - val_mae: 0.6033\n",
      "Epoch 49/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.0920 - mae: 0.2126 - val_loss: 0.7980 - val_mae: 0.5988\n",
      "Epoch 50/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.0974 - mae: 0.2160 - val_loss: 0.8073 - val_mae: 0.6028\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8155 - mae: 0.6142\n",
      "Test Loss: 0.8537367582321167\n",
      "Test MAE: 0.6227566003799438\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Encodage TF-IDF\n",
    "X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite = encode_tfidf(X_polarite, Y_polarite)\n",
    "\n",
    "# Convertir la matrice sparse en numpy array\n",
    "X_train_polarite = X_train_polarite.toarray().astype(np.float32)\n",
    "X_test_polarite = X_test_polarite.toarray().astype(np.float32)\n",
    "\n",
    "# Convertir les labels en numpy array\n",
    "Y_train_polarite = np.array(Y_train_polarite).astype(np.float32)\n",
    "Y_test_polarite = np.array(Y_test_polarite).astype(np.float32)\n",
    "\n",
    "# Définir le modèle\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_polarite.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='linear')  # Utiliser 'linear' pour une régression\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_polarite, Y_train_polarite, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss, mae = model.evaluate(X_test_polarite, Y_test_polarite)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "# Enregistrer le modèle (utiliser save() au lieu de pickle)\n",
    "os.makedirs('models2', exist_ok=True)  # Créer le dossier si inexistant\n",
    "model.save('models2/deepl_regression_tfidf.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X_train_polarite : (12776, 2)\n",
      "Dimensions de X_test_polarite : (3195, 2)\n",
      "Dimensions de Y_train_polarite : (12776,)\n",
      "Dimensions de Y_test_polarite : (3195,)\n",
      "Valeurs uniques dans Y_polarite : [1. 2. 3. 4. 5.]\n",
      "Valeurs uniques dans Y_train_polarite après recalage : [0. 1. 2. 3. 4.]\n",
      "Dimensions après One-Hot Encoding de Y_train_polarite : (12776, 5)\n",
      "Dimensions après One-Hot Encoding de Y_test_polarite : (3195, 5)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cedric\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4143 - loss: 629.7318 - val_accuracy: 0.6315 - val_loss: 1.4315\n",
      "Epoch 2/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5764 - loss: 9.8628 - val_accuracy: 0.6315 - val_loss: 1.2715\n",
      "Epoch 3/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6231 - loss: 3.0345 - val_accuracy: 0.6315 - val_loss: 1.1623\n",
      "Epoch 4/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6264 - loss: 1.8026 - val_accuracy: 0.6315 - val_loss: 1.1153\n",
      "Epoch 5/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6357 - loss: 1.3933 - val_accuracy: 0.6315 - val_loss: 1.0961\n",
      "Epoch 6/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6317 - loss: 1.3469 - val_accuracy: 0.6315 - val_loss: 1.0881\n",
      "Epoch 7/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6392 - loss: 1.2524 - val_accuracy: 0.6315 - val_loss: 1.0849\n",
      "Epoch 8/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6294 - loss: 1.2898 - val_accuracy: 0.6315 - val_loss: 1.0836\n",
      "Epoch 9/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6336 - loss: 1.1195 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 10/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6289 - loss: 1.1246 - val_accuracy: 0.6315 - val_loss: 1.0830\n",
      "Epoch 11/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6350 - loss: 1.1217 - val_accuracy: 0.6315 - val_loss: 1.0830\n",
      "Epoch 12/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6327 - loss: 1.1279 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 13/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6370 - loss: 1.1238 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 14/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6304 - loss: 1.1064 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 15/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6279 - loss: 1.1022 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 16/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6368 - loss: 1.0793 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 17/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6343 - loss: 1.1553 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 18/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6351 - loss: 1.0772 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 19/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6317 - loss: 1.0931 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 20/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6256 - loss: 1.0896 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 21/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6407 - loss: 1.0684 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 22/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6332 - loss: 1.0783 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 23/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6284 - loss: 1.0880 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 24/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6306 - loss: 1.0784 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 25/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6344 - loss: 1.2877 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 26/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6321 - loss: 1.0801 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 27/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6340 - loss: 1.0978 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 28/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6379 - loss: 1.0693 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 29/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6314 - loss: 1.0835 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 30/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6284 - loss: 1.0882 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 31/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6375 - loss: 1.0790 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 32/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6324 - loss: 1.0732 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 33/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6315 - loss: 1.0748 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 34/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6329 - loss: 1.0994 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 35/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6361 - loss: 1.0631 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 36/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6360 - loss: 1.0637 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 37/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6340 - loss: 1.0780 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 38/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6361 - loss: 1.0656 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 39/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6392 - loss: 1.0638 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 40/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6354 - loss: 1.0752 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 41/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6290 - loss: 1.0797 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 42/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6322 - loss: 1.0825 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 43/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6315 - loss: 1.0781 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 44/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6334 - loss: 1.0810 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 45/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6349 - loss: 1.0742 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 46/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6336 - loss: 1.0835 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 47/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6292 - loss: 1.0820 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 48/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6314 - loss: 1.0826 - val_accuracy: 0.6315 - val_loss: 1.0832\n",
      "Epoch 49/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6392 - loss: 1.0772 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "Epoch 50/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6431 - loss: 1.0576 - val_accuracy: 0.6315 - val_loss: 1.0831\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.6454 - loss: 1.0533\n",
      "Test Loss: 1.0747182369232178\n",
      "Test Accuracy: 0.6384976506233215\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Encodage simple\n",
    "X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite = encode_simple(X_polarite, Y_polarite)\n",
    "\n",
    "# Vérifier les dimensions de X et Y avant le traitement\n",
    "print(f\"Dimensions de X_train_polarite : {X_train_polarite.shape}\")\n",
    "print(f\"Dimensions de X_test_polarite : {X_test_polarite.shape}\")\n",
    "print(f\"Dimensions de Y_train_polarite : {Y_train_polarite.shape}\")\n",
    "print(f\"Dimensions de Y_test_polarite : {Y_test_polarite.shape}\")\n",
    "\n",
    "# Convertir en numpy arrays pour TensorFlow\n",
    "X_train_polarite = X_train_polarite.astype(np.float32)\n",
    "X_test_polarite = X_test_polarite.astype(np.float32)\n",
    "\n",
    "# Vérifier les valeurs uniques dans Y_polarite\n",
    "print(f\"Valeurs uniques dans Y_polarite : {np.unique(Y_polarite)}\")\n",
    "\n",
    "# Recalage des labels pour qu'ils commencent à 0 (les classes sont [1, 2, 3, 4, 5], il faut les transformer en [0, 1, 2, 3, 4])\n",
    "Y_train_polarite = Y_train_polarite - 1\n",
    "Y_test_polarite = Y_test_polarite - 1\n",
    "\n",
    "# Vérifier les valeurs uniques dans Y_polarite après recalage\n",
    "print(f\"Valeurs uniques dans Y_train_polarite après recalage : {np.unique(Y_train_polarite)}\")\n",
    "\n",
    "# S'assurer que les valeurs de Y_train_polarite et Y_test_polarite sont dans la plage [0, num_classes-1]\n",
    "num_classes = len(np.unique(Y_polarite))  # Nombre total de classes\n",
    "assert np.all(Y_train_polarite < num_classes), \"Certains labels sont hors de portée dans Y_train_polarite.\"\n",
    "assert np.all(Y_test_polarite < num_classes), \"Certains labels sont hors de portée dans Y_test_polarite.\"\n",
    "\n",
    "# One-hot encoding des labels multi-classes\n",
    "Y_train_polarite = to_categorical(Y_train_polarite, num_classes)\n",
    "Y_test_polarite = to_categorical(Y_test_polarite, num_classes)\n",
    "\n",
    "# Vérifier la forme de Y après le one-hot encoding\n",
    "print(f\"Dimensions après One-Hot Encoding de Y_train_polarite : {Y_train_polarite.shape}\")\n",
    "print(f\"Dimensions après One-Hot Encoding de Y_test_polarite : {Y_test_polarite.shape}\")\n",
    "\n",
    "# Définir le modèle pour classification multi-classes\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_polarite.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Softmax pour multi-classes\n",
    "])\n",
    "\n",
    "# Compiler le modèle (perte adaptée aux multi-classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_polarite, Y_train_polarite, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss, accuracy = model.evaluate(X_test_polarite, Y_test_polarite)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Enregistrer le modèle\n",
    "os.makedirs('models2', exist_ok=True)  # Créer le dossier si inexistant\n",
    "model.save('models2/deepl_classification_multi_simple.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X_train_polarite : (12776, 78362)\n",
      "Dimensions de X_test_polarite : (3195, 78362)\n",
      "Dimensions de Y_train_polarite : (12776,)\n",
      "Dimensions de Y_test_polarite : (3195,)\n",
      "Valeurs uniques dans Y_polarite : [1. 2. 3. 4. 5.]\n",
      "Valeurs uniques dans Y_train_polarite après recalage : [0. 1. 2. 3. 4.]\n",
      "Dimensions après One-Hot Encoding de Y_train_polarite : (12776, 5)\n",
      "Dimensions après One-Hot Encoding de Y_test_polarite : (3195, 5)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cedric\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.6167 - loss: 1.2120 - val_accuracy: 0.6315 - val_loss: 0.9146\n",
      "Epoch 2/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.6662 - loss: 0.7739 - val_accuracy: 0.6444 - val_loss: 0.8954\n",
      "Epoch 3/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - accuracy: 0.8081 - loss: 0.4830 - val_accuracy: 0.6318 - val_loss: 1.0517\n",
      "Epoch 4/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.8965 - loss: 0.2814 - val_accuracy: 0.6170 - val_loss: 1.2743\n",
      "Epoch 5/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.9383 - loss: 0.1747 - val_accuracy: 0.6252 - val_loss: 1.5050\n",
      "Epoch 6/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - accuracy: 0.9704 - loss: 0.1055 - val_accuracy: 0.5998 - val_loss: 1.7198\n",
      "Epoch 7/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.9815 - loss: 0.0641 - val_accuracy: 0.6252 - val_loss: 1.8702\n",
      "Epoch 8/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.9899 - loss: 0.0450 - val_accuracy: 0.6228 - val_loss: 2.0262\n",
      "Epoch 9/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9926 - loss: 0.0299 - val_accuracy: 0.6029 - val_loss: 2.0904\n",
      "Epoch 10/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 52ms/step - accuracy: 0.9934 - loss: 0.0266 - val_accuracy: 0.6256 - val_loss: 2.2003\n",
      "Epoch 11/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 68ms/step - accuracy: 0.9926 - loss: 0.0236 - val_accuracy: 0.6232 - val_loss: 2.3657\n",
      "Epoch 12/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - accuracy: 0.9967 - loss: 0.0139 - val_accuracy: 0.6092 - val_loss: 2.4614\n",
      "Epoch 13/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 69ms/step - accuracy: 0.9966 - loss: 0.0130 - val_accuracy: 0.6209 - val_loss: 2.5526\n",
      "Epoch 14/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.9956 - loss: 0.0163 - val_accuracy: 0.6232 - val_loss: 2.5888\n",
      "Epoch 15/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.6088 - val_loss: 2.6965\n",
      "Epoch 16/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.9987 - loss: 0.0081 - val_accuracy: 0.6236 - val_loss: 2.7229\n",
      "Epoch 17/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.9992 - loss: 0.0055 - val_accuracy: 0.6213 - val_loss: 2.8000\n",
      "Epoch 18/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.5998 - val_loss: 2.9539\n",
      "Epoch 19/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 92ms/step - accuracy: 0.9988 - loss: 0.0055 - val_accuracy: 0.6232 - val_loss: 2.9409\n",
      "Epoch 20/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.6287 - val_loss: 2.9424\n",
      "Epoch 21/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.9993 - loss: 0.0053 - val_accuracy: 0.6232 - val_loss: 3.0437\n",
      "Epoch 22/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.6201 - val_loss: 3.2001\n",
      "Epoch 23/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.6041 - val_loss: 3.1413\n",
      "Epoch 24/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.6232 - val_loss: 3.1655\n",
      "Epoch 25/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.6029 - val_loss: 3.1305\n",
      "Epoch 26/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 84ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.6326 - val_loss: 3.4720\n",
      "Epoch 27/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.6213 - val_loss: 3.1943\n",
      "Epoch 28/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.6170 - val_loss: 3.4297\n",
      "Epoch 29/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.6103 - val_loss: 3.4765\n",
      "Epoch 30/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - accuracy: 0.9992 - loss: 0.0064 - val_accuracy: 0.6170 - val_loss: 3.2992\n",
      "Epoch 31/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 82ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.6209 - val_loss: 3.3729\n",
      "Epoch 32/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 89ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.6193 - val_loss: 3.4586\n",
      "Epoch 33/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.6052 - val_loss: 3.5516\n",
      "Epoch 34/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.6264 - val_loss: 3.7620\n",
      "Epoch 35/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.6225 - val_loss: 3.8348\n",
      "Epoch 36/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.6225 - val_loss: 3.9314\n",
      "Epoch 37/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.6244 - val_loss: 4.0477\n",
      "Epoch 38/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.6244 - val_loss: 3.9687\n",
      "Epoch 39/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - accuracy: 0.9995 - loss: 0.0033 - val_accuracy: 0.5951 - val_loss: 3.8013\n",
      "Epoch 40/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.6150 - val_loss: 4.0031\n",
      "Epoch 41/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.6158 - val_loss: 4.0816\n",
      "Epoch 42/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - accuracy: 0.9999 - loss: 8.5813e-04 - val_accuracy: 0.6127 - val_loss: 4.1354\n",
      "Epoch 43/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.6049 - val_loss: 4.0917\n",
      "Epoch 44/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.6076 - val_loss: 4.1817\n",
      "Epoch 45/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.6127 - val_loss: 4.1323\n",
      "Epoch 46/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9993 - loss: 0.0016 - val_accuracy: 0.6217 - val_loss: 4.1787\n",
      "Epoch 47/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.5947 - val_loss: 4.3231\n",
      "Epoch 48/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0046 - val_accuracy: 0.6225 - val_loss: 4.3650\n",
      "Epoch 49/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 5.6623e-04 - val_accuracy: 0.6115 - val_loss: 4.2737\n",
      "Epoch 50/50\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.6064 - val_loss: 4.2686\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5779 - loss: 5.0851\n",
      "Test Loss: 4.855951309204102\n",
      "Test Accuracy: 0.5834115743637085\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Encodage simple\n",
    "X_train_polarite, X_test_polarite, Y_train_polarite, Y_test_polarite = encode_tfidf(X_polarite, Y_polarite)\n",
    "\n",
    "# Vérifier les dimensions de X et Y avant le traitement\n",
    "print(f\"Dimensions de X_train_polarite : {X_train_polarite.shape}\")\n",
    "print(f\"Dimensions de X_test_polarite : {X_test_polarite.shape}\")\n",
    "print(f\"Dimensions de Y_train_polarite : {Y_train_polarite.shape}\")\n",
    "print(f\"Dimensions de Y_test_polarite : {Y_test_polarite.shape}\")\n",
    "\n",
    "# Convertir en numpy arrays pour TensorFlow\n",
    "X_train_polarite = X_train_polarite.astype(np.float32)\n",
    "X_test_polarite = X_test_polarite.astype(np.float32)\n",
    "\n",
    "# Vérifier les valeurs uniques dans Y_polarite\n",
    "print(f\"Valeurs uniques dans Y_polarite : {np.unique(Y_polarite)}\")\n",
    "\n",
    "# Recalage des labels pour qu'ils commencent à 0 (les classes sont [1, 2, 3, 4, 5], il faut les transformer en [0, 1, 2, 3, 4])\n",
    "Y_train_polarite = Y_train_polarite - 1\n",
    "Y_test_polarite = Y_test_polarite - 1\n",
    "\n",
    "# Vérifier les valeurs uniques dans Y_polarite après recalage\n",
    "print(f\"Valeurs uniques dans Y_train_polarite après recalage : {np.unique(Y_train_polarite)}\")\n",
    "\n",
    "# S'assurer que les valeurs de Y_train_polarite et Y_test_polarite sont dans la plage [0, num_classes-1]\n",
    "num_classes = len(np.unique(Y_polarite))  # Nombre total de classes\n",
    "assert np.all(Y_train_polarite < num_classes), \"Certains labels sont hors de portée dans Y_train_polarite.\"\n",
    "assert np.all(Y_test_polarite < num_classes), \"Certains labels sont hors de portée dans Y_test_polarite.\"\n",
    "\n",
    "# One-hot encoding des labels multi-classes\n",
    "Y_train_polarite = to_categorical(Y_train_polarite, num_classes)\n",
    "Y_test_polarite = to_categorical(Y_test_polarite, num_classes)\n",
    "\n",
    "# Vérifier la forme de Y après le one-hot encoding\n",
    "print(f\"Dimensions après One-Hot Encoding de Y_train_polarite : {Y_train_polarite.shape}\")\n",
    "print(f\"Dimensions après One-Hot Encoding de Y_test_polarite : {Y_test_polarite.shape}\")\n",
    "\n",
    "# Définir le modèle pour classification multi-classes\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_polarite.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Softmax pour multi-classes\n",
    "])\n",
    "\n",
    "# Compiler le modèle (perte adaptée aux multi-classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_polarite, Y_train_polarite, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluer le modèle\n",
    "loss, accuracy = model.evaluate(X_test_polarite, Y_test_polarite)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Enregistrer le modèle\n",
    "os.makedirs('models2', exist_ok=True)  # Créer le dossier si inexistant\n",
    "model.save('models2/deepl_classification_multi_tfidf.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
